#### ################################################## ####
#### ############## SCRAPER FUNCTION ################## ####
#### reads a line a text file of URLs and scrapes it    ####
#### according to the CSS page element set in the above ####
#### variable. Is used in the for loops further below.  ####
#### Writing to file is set as append, so you can loop  ####
#### through multiple passes if you wish.               ####
#### ################################################## ####

library(rvest)
library(xml2)
library(readtext)
library(foreach)

#### Set the file with the URLs, the page element to be scraped, and the output file name
pageURLs <- readLines("enter file path here")
pageElement <- "enter element here"
outputFile <- "enter name of output file here.txt"


#### The scraper function ####

page.Scraper <- function(i, pageElement) {
  scrapedText<- read_html(i) %>%
    html_nodes(pageElement) %>%
    html_text() %>%
    str_trim(side = "both")
  cat(scrapedText, file = outputFile, sep = "\n", append = TRUE)
}

#### Run the function through a loop, iterating through each URL in the file ####

for (i in pageURLs) page.Scraper(i, pageElement)
